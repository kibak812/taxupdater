import sys
import os
from datetime import datetime
from typing import Dict, List, Any
import pandas as pd

# ìƒìœ„ ë””ë ‰í† ë¦¬ ëª¨ë“ˆ import
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))


class NotificationService:
    """
    ìƒˆë¡œìš´ ë°ì´í„° ë°œê²¬ ì•Œë¦¼ ë° ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤
    
    í•µì‹¬ ëª©ì : ëŒ€ìƒ ì‚¬ì´íŠ¸ì˜ ìƒˆë¡œìš´ ë°ì´í„° ì—…ë¡œë“œë¥¼ ì ì‹œì— ì‹ë³„í•˜ê³ 
    ëˆ„ë½ ì—†ëŠ” ë°ì´í„° ìˆ˜ì§‘ì„ ë³´ì¥í•˜ëŠ” ì•Œë¦¼ ì‹œìŠ¤í…œ
    """
    
    def __init__(self):
        self.site_name_mapping = {
            "tax_tribunal": "ì¡°ì„¸ì‹¬íŒì›",
            "nts_authority": "êµ­ì„¸ì²­ ìœ ê¶Œí•´ì„",
            "nts_precedent": "êµ­ì„¸ì²­ íŒë¡€",
            "moef": "ê¸°íšì¬ì •ë¶€",
            "mois": "í–‰ì •ì•ˆì „ë¶€",
            "bai": "ê°ì‚¬ì›"
        }
    
    def create_new_data_alert(self, site_key: str, new_entries: pd.DataFrame, 
                             crawling_stats: Dict[str, Any]) -> str:
        """
        ìƒˆë¡œìš´ ë°ì´í„° ë°œê²¬ ì‹œ ìƒì„¸ ì•Œë¦¼ ë©”ì‹œì§€ ìƒì„±
        
        Args:
            site_key: ì‚¬ì´íŠ¸ í‚¤
            new_entries: ìƒˆë¡œ ë°œê²¬ëœ ë°ì´í„°
            crawling_stats: í¬ë¡¤ë§ í†µê³„ ì •ë³´
            
        Returns:
            ìƒì„¸ ì•Œë¦¼ ë©”ì‹œì§€
        """
        site_name = self.site_name_mapping.get(site_key, site_key)
        
        if new_entries.empty:
            return self._create_no_new_data_message(site_name, crawling_stats)
        
        # ìƒˆë¡œìš´ ë°ì´í„° ìƒì„¸ ë¶„ì„
        new_count = len(new_entries)
        
        # ì£¼ìš” ì •ë³´ ì¶”ì¶œ
        key_info = self._extract_key_information(site_key, new_entries)
        
        # ì•Œë¦¼ ë©”ì‹œì§€ êµ¬ì„±
        alert_message = f"""ğŸš¨ ìƒˆë¡œìš´ ë°ì´í„° ë°œê²¬! ğŸš¨

ğŸ“ ì‚¬ì´íŠ¸: {site_name}
ğŸ“Š ì‹ ê·œ í•­ëª©: {new_count}ê°œ
â° íƒì§€ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ“‹ ì‹ ê·œ ë°ì´í„° ìš”ì•½:
{key_info}

ğŸ“ˆ í¬ë¡¤ë§ í†µê³„:
  â€¢ ì „ì²´ í¬ë¡¤ë§: {crawling_stats.get('total_crawled', 0)}ê°œ
  â€¢ ì‹ ê·œ ë°œê²¬: {new_count}ê°œ
  â€¢ ì¤‘ë³µ ì œì™¸: {crawling_stats.get('total_crawled', 0) - new_count}ê°œ
  â€¢ ì„±ê³µë¥ : {self._calculate_success_rate(crawling_stats)}%

âœ… ë°ì´í„° ë¬´ê²°ì„±: ëª¨ë“  ì‹ ê·œ í•­ëª©ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."""

        return alert_message
    
    def create_batch_crawling_summary(self, results: List[Dict[str, Any]]) -> str:
        """
        ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ ì‹œ ì¢…í•© ìš”ì•½ ë©”ì‹œì§€ ìƒì„±
        
        Args:
            results: ê° ì‚¬ì´íŠ¸ë³„ í¬ë¡¤ë§ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì¢…í•© ìš”ì•½ ë©”ì‹œì§€
        """
        total_new = sum(r.get('new_count', 0) for r in results)
        successful_sites = sum(1 for r in results if r.get('status') == 'success')
        total_sites = len(results)
        
        if total_new == 0:
            return self._create_no_updates_summary(results, successful_sites, total_sites)
        
        # ì‚¬ì´íŠ¸ë³„ ì‹ ê·œ ë°ì´í„° ìƒì„¸
        site_details = []
        for result in results:
            if result.get('new_count', 0) > 0:
                site_name = self.site_name_mapping.get(result['site_key'], result['site_key'])
                new_count = result['new_count']
                key_samples = result.get('key_samples', [])
                
                detail = f"  â€¢ {site_name}: {new_count}ê°œ"
                if key_samples:
                    sample_text = ", ".join(key_samples[:3])
                    if len(key_samples) > 3:
                        sample_text += f" ì™¸ {len(key_samples)-3}ê°œ"
                    detail += f" ({sample_text})"
                
                site_details.append(detail)
        
        summary = f"""ğŸ¯ ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ ë³´ê³ ì„œ

ğŸ“Š ì „ì²´ í†µê³„:
  â€¢ ì´ ì‹ ê·œ ë°ì´í„°: {total_new}ê°œ
  â€¢ ì„±ê³µí•œ ì‚¬ì´íŠ¸: {successful_sites}/{total_sites}ê°œ
  â€¢ ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ“‹ ì‚¬ì´íŠ¸ë³„ ì‹ ê·œ ë°ì´í„°:
{chr(10).join(site_details)}

âš¡ ëª¨ë‹ˆí„°ë§ ìƒíƒœ: í™œì„±
âœ… ë°ì´í„° ë¬´ê²°ì„±: ê²€ì¦ ì™„ë£Œ"""

        return summary
    
    def create_error_alert(self, site_key: str, error_details: Dict[str, Any]) -> str:
        """
        í¬ë¡¤ë§ ì‹¤íŒ¨ ì‹œ ì˜¤ë¥˜ ì•Œë¦¼ ìƒì„±
        
        Args:
            site_key: ì‚¬ì´íŠ¸ í‚¤
            error_details: ì˜¤ë¥˜ ìƒì„¸ ì •ë³´
            
        Returns:
            ì˜¤ë¥˜ ì•Œë¦¼ ë©”ì‹œì§€
        """
        site_name = self.site_name_mapping.get(site_key, site_key)
        
        error_message = f"""âš ï¸ í¬ë¡¤ë§ ì˜¤ë¥˜ ë°œìƒ âš ï¸

ğŸ“ ì‚¬ì´íŠ¸: {site_name}
ğŸš« ì˜¤ë¥˜ ìœ í˜•: {error_details.get('error_type', 'ì•Œ ìˆ˜ ì—†ìŒ')}
â° ë°œìƒ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ“ ì˜¤ë¥˜ ìƒì„¸:
{error_details.get('error_message', 'ìƒì„¸ ì •ë³´ ì—†ìŒ')}

ğŸ”„ ì¬ì‹œë„ ì •ë³´:
  â€¢ ì‹œë„ íšŸìˆ˜: {error_details.get('retry_count', 0)}íšŒ
  â€¢ ë‹¤ìŒ ì¬ì‹œë„: {error_details.get('next_retry', 'ì˜ˆì • ì—†ìŒ')}

âš ï¸ ì£¼ì˜: ë°ì´í„° ëˆ„ë½ ë°©ì§€ë¥¼ ìœ„í•´ ìˆ˜ë™ í™•ì¸ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."""

        return error_message
    
    def create_monitoring_status_report(self, repository_stats: Dict[str, Any]) -> str:
        """
        ì „ì²´ ëª¨ë‹ˆí„°ë§ ìƒíƒœ ë³´ê³ ì„œ ìƒì„±
        
        Args:
            repository_stats: ì €ì¥ì†Œ í†µê³„ ì •ë³´
            
        Returns:
            ëª¨ë‹ˆí„°ë§ ìƒíƒœ ë³´ê³ ì„œ
        """
        total_records = sum(stats.get('total_count', 0) for stats in repository_stats.values())
        
        site_status = []
        for site_key, stats in repository_stats.items():
            site_name = self.site_name_mapping.get(site_key, site_key)
            count = stats.get('total_count', 0)
            last_update = stats.get('last_updated', 'ì—†ìŒ')
            
            if isinstance(last_update, str) and last_update != 'ì—†ìŒ':
                last_update = f"ìµœê·¼ ì—…ë°ì´íŠ¸: {last_update}"
            elif last_update and last_update != 'ì—†ìŒ':
                last_update = f"ìµœê·¼ ì—…ë°ì´íŠ¸: {last_update.strftime('%Y-%m-%d %H:%M')}"
            else:
                last_update = "ì—…ë°ì´íŠ¸ ì—†ìŒ"
            
            site_status.append(f"  â€¢ {site_name}: {count:,}ê±´ ({last_update})")
        
        report = f"""ğŸ“Š ë°ì´í„° ëª¨ë‹ˆí„°ë§ í˜„í™© ë³´ê³ ì„œ

ğŸ“ˆ ì „ì²´ ìˆ˜ì§‘ í˜„í™©:
  â€¢ ì´ ìˆ˜ì§‘ ë°ì´í„°: {total_records:,}ê±´
  â€¢ ëª¨ë‹ˆí„°ë§ ì‚¬ì´íŠ¸: {len(repository_stats)}ê°œ
  â€¢ ë³´ê³ ì„œ ìƒì„±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ“‹ ì‚¬ì´íŠ¸ë³„ í˜„í™©:
{chr(10).join(site_status)}

ğŸ” ëª¨ë‹ˆí„°ë§ ëª©ì :
  â€¢ ìƒˆë¡œìš´ ë²•ë ¹ í•´ì„ ë° íŒë¡€ì˜ ì‹ ì†í•œ íƒì§€
  â€¢ ì—…ë¡œë“œ ëˆ„ë½ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì†ì  ê°ì‹œ
  â€¢ ë°ì´í„° ë¬´ê²°ì„± ë³´ì¥

âœ… ì‹œìŠ¤í…œ ìƒíƒœ: ì •ìƒ ì‘ë™ ì¤‘"""

        return report
    
    def _extract_key_information(self, site_key: str, new_data: pd.DataFrame) -> str:
        """ìƒˆë¡œìš´ ë°ì´í„°ì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ"""
        if new_data.empty:
            return "  â€¢ ì‹ ê·œ ë°ì´í„° ì—†ìŒ"
        
        info_lines = []
        
        # ì²˜ìŒ 3-5ê°œ í•­ëª©ì˜ ì£¼ìš” ì •ë³´ í‘œì‹œ
        display_count = min(5, len(new_data))
        
        for i in range(display_count):
            row = new_data.iloc[i]
            
            # ì‚¬ì´íŠ¸ë³„ ì£¼ìš” ì»¬ëŸ¼ ì„ íƒ
            if site_key == "tax_tribunal":
                key_info = f"{row.get('ì²­êµ¬ë²ˆí˜¸', 'N/A')} - {row.get('ì œëª©', 'N/A')[:50]}"
            elif site_key in ["nts_authority", "nts_precedent", "moef", "mois", "bai"]:
                key_info = f"{row.get('ë¬¸ì„œë²ˆí˜¸', 'N/A')} - {row.get('ì œëª©', 'N/A')[:50]}"
            else:
                # ê¸°ë³¸ì ìœ¼ë¡œ ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ ì»¬ëŸ¼ ì‚¬ìš©
                cols = list(row.index)
                key_info = f"{row[cols[0]]} - {row[cols[-1]][:50] if len(str(row[cols[-1]])) > 50 else row[cols[-1]]}"
            
            info_lines.append(f"  â€¢ {key_info}")
        
        if len(new_data) > display_count:
            info_lines.append(f"  â€¢ ... ì™¸ {len(new_data) - display_count}ê°œ í•­ëª©")
        
        return "\n".join(info_lines)
    
    def _create_no_new_data_message(self, site_name: str, stats: Dict[str, Any]) -> str:
        """ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ì„ ë•Œì˜ ë©”ì‹œì§€"""
        return f"""âœ… {site_name} ëª¨ë‹ˆí„°ë§ ì™„ë£Œ

ğŸ“Š í¬ë¡¤ë§ ê²°ê³¼:
  â€¢ ì‹ ê·œ ë°ì´í„°: ì—†ìŒ
  â€¢ ì „ì²´ í™•ì¸: {stats.get('total_crawled', 0)}ê°œ
  â€¢ ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%H:%M:%S')}

ğŸ” ëª¨ë‹ˆí„°ë§ ìƒíƒœ: ì •ìƒ (ìƒˆë¡œìš´ ì—…ë¡œë“œ ëŒ€ê¸° ì¤‘)"""
    
    def _create_no_updates_summary(self, results: List[Dict], successful: int, total: int) -> str:
        """ì „ì²´ í¬ë¡¤ë§ì—ì„œ ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ì„ ë•Œì˜ ìš”ì•½"""
        return f"""âœ… ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ - ì‹ ê·œ ë°ì´í„° ì—†ìŒ

ğŸ“Š ìš”ì•½:
  â€¢ ì‹ ê·œ ë°ì´í„°: ì—†ìŒ
  â€¢ ì„±ê³µí•œ ì‚¬ì´íŠ¸: {successful}/{total}ê°œ
  â€¢ ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ” ëª¨ë“  ì‚¬ì´íŠ¸ê°€ ì •ìƒì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§ë˜ì—ˆìŠµë‹ˆë‹¤.
ìƒˆë¡œìš´ ë°ì´í„° ì—…ë¡œë“œ ì‹œ ì¦‰ì‹œ ì•Œë¦¼ì´ ì œê³µë©ë‹ˆë‹¤."""
    
    def _calculate_success_rate(self, stats: Dict[str, Any]) -> float:
        """í¬ë¡¤ë§ ì„±ê³µë¥  ê³„ì‚°"""
        total = stats.get('total_attempts', stats.get('total_crawled', 1))
        successful = stats.get('successful_items', stats.get('total_crawled', 0))
        
        if total == 0:
            return 100.0
        
        return round((successful / total) * 100, 1)
    
    def get_new_data_samples(self, new_data: pd.DataFrame, site_key: str, max_samples: int = 3) -> List[str]:
        """ìƒˆë¡œìš´ ë°ì´í„°ì˜ ìƒ˜í”Œ í‚¤ ê°’ë“¤ ì¶”ì¶œ"""
        if new_data.empty:
            return []
        
        # ì‚¬ì´íŠ¸ë³„ í‚¤ ì»¬ëŸ¼ í™•ì¸
        key_column_mapping = {
            "tax_tribunal": "ì²­êµ¬ë²ˆí˜¸",
            "nts_authority": "ë¬¸ì„œë²ˆí˜¸",
            "nts_precedent": "ë¬¸ì„œë²ˆí˜¸",
            "moef": "ë¬¸ì„œë²ˆí˜¸",
            "mois": "ë¬¸ì„œë²ˆí˜¸",
            "bai": "ë¬¸ì„œë²ˆí˜¸"
        }
        
        key_column = key_column_mapping.get(site_key, "ë¬¸ì„œë²ˆí˜¸")
        
        if key_column not in new_data.columns:
            # í‚¤ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì»¬ëŸ¼ ì‚¬ìš©
            key_column = new_data.columns[0]
        
        samples = new_data[key_column].head(max_samples).tolist()
        return [str(sample) for sample in samples]