import sys
import os
from typing import Dict, Any, List
import pandas as pd

# tkinter importë¥¼ ì„ íƒì ìœ¼ë¡œ ì²˜ë¦¬ (ì›¹ í™˜ê²½ì—ì„œëŠ” ë¶ˆí•„ìš”)
try:
    from tkinter import messagebox
    TKINTER_AVAILABLE = True
except ImportError:
    TKINTER_AVAILABLE = False

# ìƒìœ„ ë””ë ‰í† ë¦¬ ëª¨ë“ˆ importë¥¼ ìœ„í•œ ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
from src.interfaces.crawler_interface import CrawlerInterface, DataRepositoryInterface
from src.services.notification_service import NotificationService


class CrawlingService:
    """
    í¬ë¡¤ë§ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì„œë¹„ìŠ¤
    
    í•µì‹¬ ëª©ì : ëŒ€ìƒ ì‚¬ì´íŠ¸ì˜ ìƒˆë¡œìš´ ë°ì´í„° ì—…ë¡œë“œë¥¼ ëˆ„ë½ì—†ì´ íƒì§€í•˜ê³ 
    ì •í™•í•œ ìƒˆë¡œìš´ ë°ì´í„° ì‹ë³„ì„ í†µí•œ ì‹¤ì‹œê°„ ì•Œë¦¼ ì‹œìŠ¤í…œ
    """
    
    def __init__(self, crawlers: Dict[str, CrawlerInterface], repository: DataRepositoryInterface):
        """
        í¬ë¡¤ë§ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            crawlers: ì‚¬ì´íŠ¸ë³„ í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ë”•ì…”ë„ˆë¦¬
            repository: ë°ì´í„° ì €ì¥ì†Œ ì¸ìŠ¤í„´ìŠ¤
        """
        self.crawlers = crawlers
        self.repository = repository
        self.notification_service = NotificationService()
    
    def execute_crawling(self, choice: str, progress, status_message, is_periodic: bool = False):
        """
        example.py ê¸°ë°˜ ìƒˆë¡œìš´ ë°ì´í„° íƒì§€ì— íŠ¹í™”ëœ í¬ë¡¤ë§ ì‹¤í–‰ ë¡œì§
        
        í•µì‹¬: ëˆ„ë½ì—†ëŠ” ë°ì´í„° ìˆ˜ì§‘ê³¼ ì •í™•í•œ ìƒˆë¡œìš´ ë°ì´í„° ì‹ë³„
        
        Args:
            choice: ì‚¬ìš©ì ì„ íƒ ("1"-"7")
            progress: ì§„í–‰ë¥  ì½œë°±
            status_message: ìƒíƒœ ë©”ì‹œì§€ ì½œë°±
            is_periodic: ì£¼ê¸°ì  ì‹¤í–‰ ì—¬ë¶€
        """
        summary_results = []
        prefix = "ì£¼ê¸°ì  í¬ë¡¤ë§ " if is_periodic else ""
        
        # ì„ íƒì— ë”°ë¥¸ í¬ë¡¤ëŸ¬ ë§¤í•‘
        crawler_mapping = {
            "1": ["tax_tribunal"],
            "2": ["nts_authority"],
            "3": ["moef"],
            "4": ["nts_precedent"],
            "5": ["mois"],
            "6": ["bai"],
            "7": ["tax_tribunal", "nts_authority", "moef", "nts_precedent", "mois", "bai"]
        }
        
        selected_crawlers = crawler_mapping.get(choice, [])
        
        if not selected_crawlers:
            self._show_message("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ìœ íš¨í•œ ì˜µì…˜ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            return
        
        print(f"\nğŸ¯ í¬ë¡¤ë§ ì‹œì‘: {len(selected_crawlers)}ê°œ ì‚¬ì´íŠ¸ ëŒ€ìƒ")
        print("=" * 60)
        
        # ì„ íƒëœ í¬ë¡¤ëŸ¬ë“¤ ìˆœì°¨ ì‹¤í–‰
        for idx, crawler_key in enumerate(selected_crawlers):
            if crawler_key in self.crawlers:
                print(f"\nğŸ“ [{idx+1}/{len(selected_crawlers)}] {crawler_key} í¬ë¡¤ë§ ì‹œì‘...")
                
                result = self._execute_single_crawler_with_detailed_logging(
                    crawler_key, progress, status_message, prefix, 
                    current_index=idx, total_count=len(selected_crawlers)
                )
                
                summary_results.append(result)
                
                # ê°œë³„ ì‚¬ì´íŠ¸ ì™„ë£Œ ì‹œ ì¦‰ì‹œ ì•Œë¦¼ (ì „ì²´ í¬ë¡¤ë§ì´ ì•„ë‹Œ ê²½ìš°)
                if choice != "7":
                    alert_message = self.notification_service.create_new_data_alert(
                        crawler_key, result.get('new_entries', pd.DataFrame()), 
                        result.get('crawling_stats', {})
                    )
                    self._show_message(alert_message)
            else:
                error_result = {
                    'site_key': crawler_key,
                    'status': 'error',
                    'error_message': f"í¬ë¡¤ëŸ¬ '{crawler_key}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    'new_count': 0
                }
                summary_results.append(error_result)
        
        # ì „ì²´ í¬ë¡¤ë§ ì¢…í•© ìš”ì•½ (choice == "7"ì¸ ê²½ìš°)
        if choice == "7":
            summary_message = self.notification_service.create_batch_crawling_summary(summary_results)
            self._show_message(summary_message)
            
            # ëª¨ë‹ˆí„°ë§ ìƒíƒœ ë³´ê³ ì„œë„ ìƒì„±
            repository_stats = {}
            for crawler_key in selected_crawlers:
                if crawler_key in self.crawlers:
                    stats = self.repository.get_statistics(crawler_key)
                    repository_stats[crawler_key] = stats
            
            monitoring_report = self.notification_service.create_monitoring_status_report(repository_stats)
            print(f"\n{monitoring_report}")
        
        print(f"\nâœ… ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ!")
        print("=" * 60)
    
    def _execute_single_crawler_with_detailed_logging(self, crawler_key: str, progress, status_message, 
                                                    prefix: str, current_index: int = 0, total_count: int = 1) -> Dict[str, Any]:
        """
        example.py ìŠ¤íƒ€ì¼ì˜ ìƒì„¸í•œ ìƒˆë¡œìš´ ë°ì´í„° íƒì§€ ë¡œì§
        
        í•µì‹¬: ëˆ„ë½ì—†ëŠ” ë°ì´í„° ìˆ˜ì§‘ê³¼ ì •í™•í•œ ìƒˆë¡œìš´ ë°ì´í„° ì‹ë³„
        """
        try:
            crawler = self.crawlers[crawler_key]
            site_name = crawler.get_site_name()
            key_column = crawler.get_key_column()
            
            # ìƒíƒœ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
            if status_message:
                status_message.config(text=f"{site_name} ë°ì´í„° í¬ë¡¤ë§ ì¤‘...")
                status_message.update()
            
            print(f"\nğŸ” {site_name} í¬ë¡¤ë§ ìƒì„¸ ë¡œê·¸:")
            print("-" * 50)
            
            # 1ë‹¨ê³„: ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ë° ë¶„ì„
            print(f"[1/4] ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì¤‘...")
            existing_data = self.repository.load_existing_data(crawler_key)
            print(f"  ğŸ“Š ê¸°ì¡´ ë°ì´í„°: {len(existing_data)}ê°œ")
            
            if not existing_data.empty:
                existing_keys = set(existing_data[key_column].astype(str))
                print(f"  ğŸ”‘ ê¸°ì¡´ í‚¤ ê°œìˆ˜: {len(existing_keys)}")
                print(f"  ğŸ“ ê¸°ì¡´ í‚¤ ìƒ˜í”Œ: {list(existing_keys)[:3]}")
            
            # 2ë‹¨ê³„: ìƒˆ ë°ì´í„° í¬ë¡¤ë§
            print(f"[2/4] {site_name} ì‚¬ì´íŠ¸ í¬ë¡¤ë§ ì¤‘...")
            if status_message:
                status_message.config(text=f"{site_name} ì‚¬ì´íŠ¸ì—ì„œ ìµœì‹  ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
                status_message.update()
            
            new_data = crawler.crawl(progress_callback=progress, status_callback=status_message)
            
            # ë°ì´í„° ìœ íš¨ì„± ê²€ì¦
            if not crawler.validate_data(new_data):
                error_msg = f"  âŒ {site_name}: í¬ë¡¤ë§ëœ ë°ì´í„°ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                print(error_msg)
                return {
                    'site_key': crawler_key,
                    'status': 'error',
                    'error_message': 'ë°ì´í„° ìœ íš¨ì„± ê²€ì¦ ì‹¤íŒ¨',
                    'new_count': 0,
                    'total_crawled': 0
                }
            
            if new_data.empty:
                error_msg = f"  âš ï¸  {site_name}: í¬ë¡¤ë§ ê²°ê³¼ ë°ì´í„° ì—†ìŒ."
                print(error_msg)
                return {
                    'site_key': crawler_key,
                    'status': 'error',
                    'error_message': 'í¬ë¡¤ë§ ê²°ê³¼ ì—†ìŒ',
                    'new_count': 0,
                    'total_crawled': 0
                }
            
            print(f"  âœ… í¬ë¡¤ë§ ì™„ë£Œ: {len(new_data)}ê°œ í•­ëª© ìˆ˜ì§‘")
            
            # 3ë‹¨ê³„: example.py ìŠ¤íƒ€ì¼ì˜ ìƒì„¸í•œ ìƒˆë¡œìš´ ë°ì´í„° íƒì§€ ë¡œì§
            print(f"[3/4] ìƒˆë¡œìš´ ë°ì´í„° íƒì§€ ë° ë¶„ì„...")
            if status_message:
                status_message.config(text=f"{site_name} ìƒˆë¡œìš´ ë°ì´í„° ë¶„ì„ ì¤‘...")
                status_message.update()
            
            # example.pyì˜ compare_data ë¡œì§ì„ ì •í™•íˆ ì¬í˜„
            print(f"  [DEBUG] compare_data ìŠ¤íƒ€ì¼ ë¶„ì„:")
            print(f"    ê¸°ì¡´ ë°ì´í„°: {len(existing_data)}ê°œ")
            print(f"    ìƒˆ ë°ì´í„°: {len(new_data)}ê°œ")
            
            if existing_data.empty:
                new_entries = new_data
                print(f"    â¡ï¸  ê¸°ì¡´ ë°ì´í„° ì—†ìŒ, ëª¨ë“  {len(new_data)}ê°œê°€ ì‹ ê·œ ë°ì´í„°")
            else:
                # í‚¤ ì§‘í•© ë¶„ì„ (example.pyì™€ ë™ì¼í•œ ë°©ì‹)
                existing_keys = set(existing_data[key_column].astype(str))
                new_keys = set(new_data[key_column].astype(str))
                
                print(f"    ê¸°ì¡´ í‚¤ ê°œìˆ˜: {len(existing_keys)}")
                print(f"    ìƒˆ í‚¤ ê°œìˆ˜: {len(new_keys)}")
                print(f"    ê¸°ì¡´ í‚¤ ìƒ˜í”Œ: {list(existing_keys)[:3]}")
                print(f"    ìƒˆ í‚¤ ìƒ˜í”Œ: {list(new_keys)[:3]}")
                
                # ì°¨ì§‘í•© ê³„ì‚° (example.pyì™€ ë™ì¼)
                new_only = new_keys - existing_keys
                existing_only = existing_keys - new_keys
                common = existing_keys & new_keys
                
                print(f"    ìƒˆ ë°ì´í„°ì—ë§Œ ìˆëŠ” í‚¤: {len(new_only)}ê°œ")
                print(f"    ê¸°ì¡´ ë°ì´í„°ì—ë§Œ ìˆëŠ” í‚¤: {len(existing_only)}ê°œ")
                print(f"    ê³µí†µ í‚¤: {len(common)}ê°œ")
                
                if len(new_only) > 0:
                    print(f"    ğŸ†• ìƒˆ í‚¤ ìƒ˜í”Œ: {list(new_only)[:5]}")
                if len(existing_only) > 0:
                    print(f"    ğŸ“ ê¸°ì¡´ ì „ìš© í‚¤ ìƒ˜í”Œ: {list(existing_only)[:5]}")
                
                # SQLite Repositoryì˜ ê³ ì„±ëŠ¥ ë¹„êµ ë¡œì§ ì‚¬ìš©
                new_entries = self.repository.compare_and_get_new_entries(
                    crawler_key, new_data, key_column
                )
                
                print(f"    ìµœì¢… ìƒˆ í•­ëª©: {len(new_entries)}ê°œ")
            
            # 4ë‹¨ê³„: ë°ì´í„° ì €ì¥ ë° ë°±ì—…
            print(f"[4/4] ë°ì´í„° ì €ì¥ ë° ë°±ì—…...")
            crawling_stats = {
                'total_crawled': len(new_data),
                'existing_count': len(existing_data),
                'new_count': len(new_entries),
                'success_rate': 100.0,
                'site_name': site_name
            }
            
            if not new_entries.empty:
                if status_message:
                    status_message.config(text=f"{site_name} ìƒˆë¡œìš´ ë°ì´í„° {len(new_entries)}ê°œ ì €ì¥ ì¤‘...")
                    status_message.update()
                
                # ë°±ì—… ìƒì„±
                backup_path = self.repository.backup_data(crawler_key, new_entries)
                print(f"  ğŸ’¾ ë°±ì—… ì™„ë£Œ: {backup_path}")
                
                # ë°ì´í„° ì €ì¥ (ì¦ë¶„ ì €ì¥)
                save_success = self.repository.save_data(crawler_key, new_data, is_incremental=True)
                
                if save_success:
                    print(f"  âœ… ì €ì¥ ì™„ë£Œ: {len(new_entries)}ê°œ ì‹ ê·œ í•­ëª©")
                    
                    # ìƒ˜í”Œ ìƒˆ ë°ì´í„° ì •ë³´ ì¶œë ¥
                    samples = self.notification_service.get_new_data_samples(new_entries, crawler_key, 3)
                    if samples:
                        print(f"  ğŸ“‹ ì‹ ê·œ ë°ì´í„° ìƒ˜í”Œ: {', '.join(samples)}")
                else:
                    print(f"  âŒ ì €ì¥ ì‹¤íŒ¨")
                    return {
                        'site_key': crawler_key,
                        'status': 'error',
                        'error_message': 'ë°ì´í„° ì €ì¥ ì‹¤íŒ¨',
                        'new_count': len(new_entries),
                        'total_crawled': len(new_data)
                    }
            else:
                print(f"  âœ… ìƒˆë¡œìš´ ë°ì´í„° ì—†ìŒ (ëª¨ë“  ë°ì´í„°ê°€ ê¸°ì¡´ì— ì¡´ì¬)")
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            if progress:
                overall_progress = int(((current_index + 1) / total_count) * 100)
                progress['value'] = overall_progress
                progress.update()
            
            if status_message:
                status_message.config(text=f"{site_name} ì™„ë£Œ: ì‹ ê·œ {len(new_entries)}ê°œ")
                status_message.update()
            
            print(f"  ğŸ¯ {site_name} í¬ë¡¤ë§ ì™„ë£Œ!")
            print(f"    ì „ì²´ ìˆ˜ì§‘: {len(new_data)}ê°œ")
            print(f"    ì‹ ê·œ ë°œê²¬: {len(new_entries)}ê°œ")
            print(f"    ì¤‘ë³µ ì œì™¸: {len(new_data) - len(new_entries)}ê°œ")
            
            return {
                'site_key': crawler_key,
                'status': 'success',
                'new_count': len(new_entries),
                'total_crawled': len(new_data),
                'existing_count': len(existing_data),
                'new_entries': new_entries,
                'crawling_stats': crawling_stats,
                'key_samples': self.notification_service.get_new_data_samples(new_entries, crawler_key, 5)
            }
                
        except Exception as e:
            error_msg = f"  âŒ {crawler_key} í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            print(error_msg)
            
            # ì˜¤ë¥˜ ì•Œë¦¼ ìƒì„±
            error_alert = self.notification_service.create_error_alert(
                crawler_key, 
                {
                    'error_type': type(e).__name__,
                    'error_message': str(e),
                    'retry_count': 0,
                    'next_retry': 'ìˆ˜ë™ ì¬ì‹œë„ í•„ìš”'
                }
            )
            print(f"\n{error_alert}")
            
            return {
                'site_key': crawler_key,
                'status': 'error',
                'error_message': str(e),
                'new_count': 0,
                'total_crawled': 0
            }
    
    def get_crawler_statistics(self) -> Dict[str, Any]:
        """ëª¨ë“  í¬ë¡¤ëŸ¬ì˜ í†µê³„ ì •ë³´ ë°˜í™˜"""
        stats = {}
        for crawler_key, crawler in self.crawlers.items():
            try:
                site_name = crawler.get_site_name()
                repo_stats = self.repository.get_statistics(crawler_key)
                stats[site_name] = repo_stats
            except Exception as e:
                stats[crawler_key] = {"error": str(e)}
        return stats
    
    def get_monitoring_summary(self) -> str:
        """ì „ì²´ ëª¨ë‹ˆí„°ë§ í˜„í™© ìš”ì•½ ë°˜í™˜"""
        repository_stats = {}
        for crawler_key in self.crawlers.keys():
            stats = self.repository.get_statistics(crawler_key)
            repository_stats[crawler_key] = stats
        
        return self.notification_service.create_monitoring_status_report(repository_stats)
    
    def test_new_data_detection(self, crawler_key: str) -> Dict[str, Any]:
        """ìƒˆë¡œìš´ ë°ì´í„° íƒì§€ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ (ê°œë°œ/ë””ë²„ê¹…ìš©)"""
        if crawler_key not in self.crawlers:
            return {"error": f"í¬ë¡¤ëŸ¬ '{crawler_key}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        
        print(f"\nğŸ§ª {crawler_key} ìƒˆë¡œìš´ ë°ì´í„° íƒì§€ í…ŒìŠ¤íŠ¸")
        print("=" * 50)
        
        try:
            # ì‹¤ì œ í¬ë¡¤ë§ ì‹¤í–‰í•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„° íƒì§€ í…ŒìŠ¤íŠ¸
            result = self._execute_single_crawler_with_detailed_logging(
                crawler_key, None, None, "í…ŒìŠ¤íŠ¸: ", 0, 1
            )
            
            test_result = {
                "crawler_key": crawler_key,
                "test_status": "success",
                "new_data_detected": result.get('new_count', 0),
                "total_crawled": result.get('total_crawled', 0),
                "detection_accuracy": "ì •ìƒ" if result.get('status') == 'success' else "ì˜¤ë¥˜",
                "test_timestamp": pd.Timestamp.now()
            }
            
            print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
            print(f"  ìƒˆë¡œìš´ ë°ì´í„° íƒì§€: {test_result['new_data_detected']}ê°œ")
            print(f"  ì „ì²´ ìˆ˜ì§‘: {test_result['total_crawled']}ê°œ")
            print(f"  íƒì§€ ì •í™•ë„: {test_result['detection_accuracy']}")
            
            return test_result
            
        except Exception as e:
            error_result = {
                "crawler_key": crawler_key,
                "test_status": "error",
                "error_message": str(e),
                "test_timestamp": pd.Timestamp.now()
            }
            print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
            return error_result
    
    def _show_message(self, message):
        """ë©”ì‹œì§€ í‘œì‹œ"""
        if TKINTER_AVAILABLE:
            messagebox.showinfo("í¬ë¡¤ë§ ì™„ë£Œ", message)
        else:
            print(f"[ì•Œë¦¼] í¬ë¡¤ë§ ì™„ë£Œ: {message}")